"""
CHRONEX AI - Python Backend
Advanced AI Assistant with NLP, ML, and Code Analysis
Python: 3.8+
Requirements: flask, nltk, requests, numpy, python-dotenv, openai, pillow
Creator: DEMON ALEX - CREATOR OF CHRONEX AI
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
import json
import os
import random
import string
from datetime import datetime
import logging
import base64
from pathlib import Path

# Try importing AI libraries
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    from transformers import pipeline
    HUGGINGFACE_AVAILABLE = True
except ImportError:
    HUGGINGFACE_AVAILABLE = False

try:
    from PIL import Image
    PILLOW_AVAILABLE = True
except ImportError:
    PILLOW_AVAILABLE = False

try:
    from dotenv import load_dotenv
    load_dotenv()
    DOTENV_AVAILABLE = True
except ImportError:
    DOTENV_AVAILABLE = False

# Import boolean type
try:
    from distutils.util import strtobool as to_bool
except ImportError:
    def to_bool(val):
        return str(val).lower() in ('yes', 'true', 't', '1', 'on')

# ============ IMAGE PROCESSING SYSTEM ============
class ImageProcessor:
    """Handle image uploads and analysis"""
    def __init__(self, upload_dir="uploads/images"):
        self.upload_dir = upload_dir
        self.allowed_extensions = {'png', 'jpg', 'jpeg', 'gif', 'webp', 'bmp'}
        self.max_file_size = 10 * 1024 * 1024  # 10MB
        
        # Create upload directory
        Path(self.upload_dir).mkdir(parents=True, exist_ok=True)
        logger.info(f"‚úÖ Image processor initialized. Upload dir: {self.upload_dir}")
    
    def allowed_file(self, filename):
        """Check if file is allowed"""
        return '.' in filename and filename.rsplit('.', 1)[1].lower() in self.allowed_extensions
    
    def save_image(self, file):
        """Save uploaded image and return path"""
        try:
            if not self.allowed_file(file.filename):
                return None, "File type not allowed. Use: PNG, JPG, GIF, WEBP, BMP"
            
            if len(file.getvalue()) > self.max_file_size:
                return None, f"File too large. Max size: 10MB"
            
            # Generate unique filename
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{timestamp}_{file.filename}"
            filepath = os.path.join(self.upload_dir, filename)
            
            # Save file
            file.save(filepath)
            logger.info(f"‚úÖ Image saved: {filepath}")
            
            return filepath, "Success"
        except Exception as e:
            logger.error(f"‚ùå Error saving image: {e}")
            return None, str(e)
    
    def get_image_base64(self, filepath):
        """Convert image to base64 for API sending"""
        try:
            with open(filepath, "rb") as image_file:
                return base64.b64encode(image_file.read()).decode('utf-8')
        except Exception as e:
            logger.error(f"‚ùå Error encoding image: {e}")
            return None
    
    def analyze_image_openai(self, filepath):
        """Analyze image using OpenAI Vision"""
        try:
            if not OPENAI_AVAILABLE:
                return None
            
            base64_image = self.get_image_base64(filepath)
            if not base64_image:
                return None
            
            response = openai.ChatCompletion.create(
                model="gpt-4-vision-preview",
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": "Please analyze this image in detail. What do you see? Describe objects, text, composition, and any notable features."},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{base64_image}"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=1000
            )
            
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"‚ùå OpenAI image analysis error: {e}")
            return None
    
    def analyze_image_basic(self, filepath):
        """Basic image analysis using PIL"""
        try:
            if not PILLOW_AVAILABLE:
                return None
            
            img = Image.open(filepath)
            width, height = img.size
            format_type = img.format
            mode = img.mode
            
            analysis = f"""üì∏ **Image Analysis (Basic)**

**File Information:**
‚Ä¢ Format: {format_type}
‚Ä¢ Dimensions: {width}x{height} pixels
‚Ä¢ Color Mode: {mode}
‚Ä¢ File Size: {os.path.getsize(filepath) / 1024:.1f} KB

**Description:**
Image successfully scanned and processed. For detailed AI analysis, use OpenAI Vision API.

**Next Steps:**
1. Upload to OpenAI for detailed analysis
2. Extract text from image (OCR)
3. Identify objects and scenes
4. Generate image captions"""
            
            return analysis
        except Exception as e:
            logger.error(f"‚ùå Image analysis error: {e}")
            return None

# Initialize Image Processor
image_processor = ImageProcessor()

# ============ CONFIGURATION MANAGER ============
class ConfigManager:
    """Manages AI configuration from multiple sources"""
    def __init__(self):
        self.config = self.load_config()
    
    def load_config(self):
        """Load config from .env, config.json, or defaults"""
        config = {
            "ai_provider": os.getenv("AI_PROVIDER", "openai"),  # openai, huggingface, ollama, default
            "openai_api_key": os.getenv("OPENAI_API_KEY", ""),
            "openai_model": os.getenv("OPENAI_MODEL", "gpt-3.5-turbo"),
            "huggingface_model": os.getenv("HF_MODEL", "gpt2"),
            "ollama_endpoint": os.getenv("OLLAMA_ENDPOINT", "http://localhost:11434"),
            "temperature": float(os.getenv("AI_TEMPERATURE", "0.7")),
            "max_tokens": int(os.getenv("AI_MAX_TOKENS", "1000")),
            "use_real_ai": to_bool(os.getenv("USE_REAL_AI", "True")),
            "enable_vision": to_bool(os.getenv("ENABLE_VISION", "True")),
        }
        
        # Try loading from config.json
        if os.path.exists("config.json"):
            try:
                with open("config.json", "r") as f:
                    json_config = json.load(f)
                    config.update(json_config)
                logger.info("‚úÖ Config loaded from config.json")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Could not load config.json: {e}")
        
        return config
    
    def get(self, key, default=None):
        """Get configuration value"""
        return self.config.get(key, default)
    
    def set(self, key, value):
        """Set configuration value"""
        self.config[key] = value

# Initialize Config Manager
config_manager = ConfigManager()

# ============ REAL AI PROVIDERS ============
class RealAIProvider:
    """Handles real AI responses from various providers"""
    
    def __init__(self, config):
        self.config = config
        self.provider = config.get("ai_provider", "openai")
        self.setup_provider()
    
    def setup_provider(self):
        """Setup the AI provider"""
        if self.provider == "openai" and OPENAI_AVAILABLE:
            openai.api_key = self.config.get("openai_api_key", "")
            logger.info("‚úÖ OpenAI provider initialized")
        elif self.provider == "huggingface" and HUGGINGFACE_AVAILABLE:
            self.pipe = pipeline("text-generation", model=self.config.get("huggingface_model", "gpt2"))
            logger.info("‚úÖ Hugging Face provider initialized")
        else:
            logger.warning("‚ö†Ô∏è No real AI provider available, using default responses")
    
    def generate_response(self, message, context=""):
        """Generate real AI response"""
        try:
            if not self.config.get("use_real_ai", True):
                return None
            
            if self.provider == "openai" and OPENAI_AVAILABLE:
                return self.openai_response(message, context)
            elif self.provider == "huggingface" and HUGGINGFACE_AVAILABLE:
                return self.huggingface_response(message)
            elif self.provider == "ollama":
                return self.ollama_response(message)
            else:
                return None
        except Exception as e:
            logger.error(f"‚ùå AI Provider error: {e}")
            return None
    
    def openai_response(self, message, context=""):
        """Get response from OpenAI API"""
        try:
            response = openai.ChatCompletion.create(
                model=self.config.get("openai_model", "gpt-3.5-turbo"),
                messages=[
                    {"role": "system", "content": f"You are Chronex AI, an advanced assistant. Context: {context}"},
                    {"role": "user", "content": message}
                ],
                temperature=self.config.get("temperature", 0.7),
                max_tokens=self.config.get("max_tokens", 1000)
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"OpenAI error: {e}")
            return None
    
    def huggingface_response(self, message):
        """Get response from Hugging Face model"""
        try:
            result = self.pipe(message, max_length=self.config.get("max_tokens", 1000))
            return result[0]['generated_text']
        except Exception as e:
            logger.error(f"Hugging Face error: {e}")
            return None
    
    def ollama_response(self, message):
        """Get response from Ollama (local model)"""
        try:
            import requests
            response = requests.post(
                f"{self.config.get('ollama_endpoint')}/api/generate",
                json={"prompt": message, "stream": False},
                timeout=30
            )
            return response.json().get("response")
        except Exception as e:
            logger.error(f"Ollama error: {e}")
            return None

# ============ RANDOM RESPONSE GENERATOR ============
def def_random(response_list):
    """
    Generates random varied responses from a list
    Ensures no two consecutive messages are identical
    """
    if not response_list or len(response_list) == 0:
        return "I'm here to help! What would you like to know?"
    return random.choice(response_list)

# ============ CREATOR LIBRARY STORAGE ============
class CreatorLibrary:
    """
    Library to store and manage creator information and metadata
    Persists data to JSON file for later retrieval
    """
    def __init__(self, storage_file="creator_library.json"):
        self.storage_file = storage_file
        self.creator_data = {
            "primary_creator": "DEMON ALEX",
            "secondary_creator": "DEVELOPER OF NEXCHAT",
            "system": "Chronex AI",
            "version": "1.0",
            "created_date": datetime.now().isoformat(),
            "metadata": {},
            "query_history": [],
            "stored_info": {}
        }
        self.load_library()
    
    def load_library(self):
        """Load existing library from file if it exists"""
        if os.path.exists(self.storage_file):
            try:
                with open(self.storage_file, 'r') as f:
                    self.creator_data = json.load(f)
                logger.info(f"‚úÖ Creator library loaded from {self.storage_file}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Could not load library: {e}. Creating new one.")
                self.save_library()
        else:
            self.save_library()
    
    def save_library(self):
        """Save library data to JSON file"""
        try:
            with open(self.storage_file, 'w') as f:
                json.dump(self.creator_data, f, indent=2)
            logger.info(f"üíæ Creator library saved to {self.storage_file}")
        except Exception as e:
            logger.error(f"‚ùå Error saving library: {e}")
    
    def add_query(self, query, response_type="general"):
        """Add a query to history"""
        query_entry = {
            "timestamp": datetime.now().isoformat(),
            "query": query,
            "type": response_type
        }
        self.creator_data["query_history"].append(query_entry)
        self.save_library()
    
    def store_info(self, key, value):
        """Store custom information in library"""
        self.creator_data["stored_info"][key] = {
            "value": value,
            "timestamp": datetime.now().isoformat()
        }
        self.save_library()
    
    def get_creator_info(self):
        """Get comprehensive creator information"""
        return {
            "primary_creator": self.creator_data["primary_creator"],
            "secondary_creator": self.creator_data["secondary_creator"],
            "system": self.creator_data["system"],
            "version": self.creator_data["version"],
            "created_date": self.creator_data["created_date"],
            "total_queries": len(self.creator_data["query_history"]),
            "stored_items": len(self.creator_data["stored_info"])
        }
    
    def get_query_history(self, limit=10):
        """Get recent query history"""
        return self.creator_data["query_history"][-limit:]
    
    def get_stored_info(self, key=None):
        """Get stored information"""
        if key:
            return self.creator_data["stored_info"].get(key)
        return self.creator_data["stored_info"]
    
    def clear_history(self):
        """Clear query history"""
        self.creator_data["query_history"] = []
        self.save_library()
    
    def export_library(self):
        """Export entire library as dictionary"""
        return self.creator_data

app = Flask(__name__)
CORS(app)

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ============ CREATOR INFO ============
CREATOR = "DEMON ALEX"
SECONDARY_CREATOR = "DEVELOPER OF NEXCHAT"

# Initialize Creator Library
creator_library = CreatorLibrary()

def creator():
    """Get creator information"""
    return {
        "primary_creator": CREATOR,
        "secondary_creator": SECONDARY_CREATOR,
        "role": "Developer",
        "system": "Chronex AI Python Backend",
        "version": ""
    }

# ============ CHRONEX AI CONFIGURATION ============
CHRONEX_CONFIG = {
    "creator": CREATOR,
    "parameters": {
        "model_size": 4_000_000_000,
        "max_processing_limit": 4_000_000_000,
        "hidden_layers": 96,
        "attention_heads": 64,
        "ffn_hidden_size": 16000,
        "vocab_size": 128256,
        "context_length": 32768,
        "description": "4B parameter model"
    },
    "model": {
        "name": "Chronex AI (Python 4B)",
        "type": "advanced-neural-network",
        "parameters": 4_000_000_000,
        "temperature": 0.7,
        "max_tokens": 2000,
        "top_p": 0.9,
    },
    "capabilities": {
        "chat": True,
        "code_analysis": True,
        "language_support": ["JavaScript", "Python", "C++", "C","Java", "Go", "Rust"],
        "math_solving": True,
        "data_analysis": True,
    },
    "safety": {
        "content_moderation": True,
        "auto_filter": True,
    }
}

# ============ ENHANCED NLP & INTENT SYSTEM ============
class IntentClassifier:
    """Advanced intent classification for smarter AI responses"""
    
    def __init__(self):
        self.intents = {
            "greeting": ["hello", "hi", "hey", "greetings", "good morning", "good afternoon", "good evening"],
            "question": ["what", "why", "how", "when", "where", "who", "which", "can you", "could you"],
            "coding": ["code", "function", "class", "variable", "bug", "error", "debug", "compile", "syntax"],
            "math": ["calculate", "solve", "equation", "formula", "math", "algebra", "calculus", "derivative", "integral"],
            "explanation": ["explain", "describe", "tell me about", "what is", "define", "meaning"],
            "help": ["help", "assist", "support", "guide", "teach", "show me"],
            "creative": ["create", "generate", "build", "design", "make", "develop"],
            "analysis": ["analyze", "review", "evaluate", "assess", "examine", "check"],
        }
        
    def detect_intent(self, message):
        """Detect user's intent from message"""
        msg_lower = message.lower()
        detected = []
        
        for intent, keywords in self.intents.items():
            if any(keyword in msg_lower for keyword in keywords):
                detected.append(intent)
        
        return detected if detected else ["general"]
    
    def extract_entities(self, message):
        """Extract important entities from message"""
        entities = {
            "languages": [],
            "topics": [],
            "numbers": []
        }
        
        # Programming languages
        langs = ["python", "javascript", "java", "c++", "c#", "ruby", "go", "rust", "php", "typescript"]
        for lang in langs:
            if lang in message.lower():
                entities["languages"].append(lang)
        
        # Topics
        topics = ["ai", "machine learning", "data science", "web", "mobile", "database", "api", "cloud"]
        for topic in topics:
            if topic in message.lower():
                entities["topics"].append(topic)
        
        # Extract numbers (simple regex would be better)
        import re
        numbers = re.findall(r'\d+(?:\.\d+)?', message)
        entities["numbers"] = numbers
        
        return entities

# ============ ENHANCED KNOWLEDGE ENGINE ============
class KnowledgeEngine:
    """Advanced knowledge base with contextual retrieval"""
    
    def __init__(self):
        self.knowledge_base = self._build_knowledge_base()
        
    def _build_knowledge_base(self):
        """Build comprehensive knowledge base"""
        return {
            "programming_concepts": {
                "variables": "Variables store data values. In Python: `x = 10` creates a variable. Use descriptive names!",
                "functions": "Functions are reusable code blocks. Define with `def name(params):` in Python or `function name(params) {}` in JavaScript.",
                "loops": "Loops repeat code. `for` loops iterate over sequences, `while` loops continue while condition is true.",
                "classes": "Classes define objects with properties and methods. Use OOP for structured, maintainable code.",
                "async": "Asynchronous programming handles operations without blocking. Use `async/await` for cleaner async code.",
            },
            "ai_ml": {
                "neural_networks": "Neural networks are AI models inspired by the brain. Layers of neurons process data, learning patterns through training.",
                "deep_learning": "Deep learning uses multi-layer neural networks for complex pattern recognition in images, text, and more.",
                "nlp": "Natural Language Processing enables computers to understand human language through tokenization, embeddings, and transformers.",
                "computer_vision": "Computer vision teaches machines to interpret visual data using CNNs for image classification and object detection.",
            },
            "data_structures": {
                "arrays": "Arrays store ordered collections. Fast access by index O(1), but insertion/deletion can be O(n).",
                "linked_lists": "Linked lists use nodes with pointers. Efficient insertion O(1) but slower access O(n).",
                "hash_maps": "Hash maps (dictionaries) provide O(1) average lookup using key-value pairs with hashing.",
                "trees": "Trees are hierarchical structures. Binary search trees enable O(log n) search with proper balancing.",
                "graphs": "Graphs represent networks with nodes and edges. Use for social networks, maps, dependencies.",
            },
            "algorithms": {
                "sorting": "Common algorithms: QuickSort O(n log n) average, MergeSort O(n log n) guaranteed, BubbleSort O(n¬≤).",
                "searching": "Binary search O(log n) on sorted data. Linear search O(n) for unsorted. Hash lookup O(1) average.",
                "dynamic_programming": "DP optimizes by storing subproblem solutions. Break problems into overlapping subproblems.",
                "greedy": "Greedy algorithms make locally optimal choices. Works for problems with greedy-choice property.",
            }
        }
    
    def search(self, query):
        """Search knowledge base for relevant information"""
        query_lower = query.lower()
        results = []
        
        for category, items in self.knowledge_base.items():
            for topic, info in items.items():
                if topic in query_lower or any(word in query_lower for word in topic.split('_')):
                    results.append({
                        "category": category,
                        "topic": topic,
                        "information": info
                    })
        
        return results

# ============ CHRONEX AI CLASS (ENHANCED) ============
class ChronexAIPython:
    def __init__(self, config_obj=None):
        self.config = config_obj or CHRONEX_CONFIG
        self.conversation_history = []
        self.user_context = {}  # Store user-specific context
        self.ai_provider = RealAIProvider(config_manager.config)
        self.use_real_ai = config_manager.get("use_real_ai", True)
        
        # Initialize enhanced components
        self.intent_classifier = IntentClassifier()
        self.knowledge_engine = KnowledgeEngine()
        
        logger.info(f"üß† ChronexAI Enhanced - Using Real AI: {self.use_real_ai}")

    def analyze_message(self, message):
        """Deep analysis of user message"""
        analysis = {
            "intents": self.intent_classifier.detect_intent(message),
            "entities": self.intent_classifier.extract_entities(message),
            "complexity": self._assess_complexity(message),
            "knowledge_matches": self.knowledge_engine.search(message),
        }
        return analysis
    
    def _assess_complexity(self, message):
        """Assess message complexity"""
        word_count = len(message.split())
        has_technical = any(word in message.lower() for word in 
                          ["algorithm", "optimize", "architecture", "implementation"])
        
        if word_count > 50 or has_technical:
            return "advanced"
        elif word_count > 20:
            return "intermediate"
        else:
            return "simple"

    def get_ai_response(self, message, context="", analysis=None):
        """Get response from real AI - ENHANCED WITH CONTEXT"""
        if self.use_real_ai:
            # Build enriched context
            enriched_context = context
            if analysis:
                enriched_context += f"\n\nIntent: {', '.join(analysis['intents'])}"
                if analysis['entities']['languages']:
                    enriched_context += f"\nProgramming Languages: {', '.join(analysis['entities']['languages'])}"
                if analysis['knowledge_matches']:
                    enriched_context += f"\nRelevant Topics: {', '.join([m['topic'] for m in analysis['knowledge_matches'][:3]])}"
            
            real_response = self.ai_provider.generate_response(message, enriched_context)
            if real_response:
                logger.info(f"‚úÖ Real AI response generated with context")
                return real_response
        
        # Intelligent fallback using analysis
        logger.info(f"‚ö° Using intelligent context-aware fallback")
        return None

    def generate_smart_response(self, message, analysis):
        """Generate intelligent response based on analysis"""
        intents = analysis['intents']
        entities = analysis['entities']
        knowledge = analysis['knowledge_matches']
        
        # Use knowledge base if we have matches
        if knowledge:
            kb_info = knowledge[0]['information']
            return f"""üí° **{knowledge[0]['topic'].replace('_', ' ').title()}**\n\n{kb_info}\n\n{'**Related to:** ' + ', '.join(entities['languages']) if entities['languages'] else ''}\n\nWould you like me to explain more details or provide code examples?"""
        
        # Intent-based responses
        if "coding" in intents:
            langs = entities['languages']
            lang_str = f" in {', '.join(langs)}" if langs else ""
            return f"""üíª **Code Assistance{lang_str}**\n\nI can help you with:\n‚Ä¢ Writing and reviewing code\n‚Ä¢ Debugging and optimization\n‚Ä¢ Best practices and patterns\n‚Ä¢ Algorithm implementation\n\nWhat specifically would you like help with?"""
        
        if "math" in intents:
            numbers = entities['numbers']
            num_str = f" with numbers {', '.join(numbers)}" if numbers else ""
            return f"""üî¢ **Mathematical Assistance{num_str}**\n\nI can solve:\n‚Ä¢ Algebraic equations\n‚Ä¢ Calculus problems\n‚Ä¢ Statistics and probability\n‚Ä¢ Linear algebra\n\nPlease share the complete problem and I'll solve it step-by-step!"""
        
        if "explanation" in intents:
            topics = entities['topics']
            topic_str = f" about {', '.join(topics)}" if topics else ""
            return f"""üìö **Explanation Mode{topic_str}**\n\nI'll break this down clearly:\n‚Ä¢ Fundamental concepts\n‚Ä¢ Practical examples\n‚Ä¢ Real-world applications\n‚Ä¢ Further resources\n\nWhat specifically would you like me to explain?"""
        
        # General intelligent response
        return f"""üß† **Intelligent Response Mode**\n\nI understand you're asking about: {message[:100]}{'...' if len(message) > 100 else ''}\n\nBased on my analysis:\n‚Ä¢ Intent: {', '.join(intents)}\n{f"‚Ä¢ Languages: {', '.join(entities['languages'])}" if entities['languages'] else ''}\n{f"‚Ä¢ Topics: {', '.join(entities['topics'])}" if entities['topics'] else ''}\n\nI'm ready to provide detailed assistance. Could you provide more specifics so I can give you the best answer?"""

    def process_message(self, message, conversation_history=None):
        """Process incoming message with ENHANCED intelligence"""
        try:
            # Add to history
            if conversation_history is None:
                conversation_history = []
            
            conversation_history.append({
                "role": "user",
                "content": message,
                "timestamp": datetime.now().isoformat()
            })

            # DEEP MESSAGE ANALYSIS
            analysis = self.analyze_message(message)
            logger.info(f"üìä Analysis: Intents={analysis['intents']}, Entities={analysis['entities']}")

            # Build rich conversation context
            recent_context = "\n".join([
                f"{msg.get('role', 'user')}: {msg.get('content', '')}"
                for msg in conversation_history[-5:]
            ])

            # Try real AI first with ENHANCED context
            context = f"""You are Chronex AI, an advanced intelligent assistant created by DEMON ALEX.
Be helpful, accurate, and conversational.

Recent conversation:
{recent_context}

Analysis:
- User Intent: {', '.join(analysis['intents'])}
- Complexity: {analysis['complexity']}
- Entities: {analysis['entities']}"""

            real_response = self.get_ai_response(message, context, analysis)
            
            if real_response:
                response = real_response
            else:
                # Use intelligent fallback with analysis
                response = self.generate_smart_response(message, analysis)

            # Add AI response to history
            conversation_history.append({
                "role": "assistant",
                "content": response,
                "timestamp": datetime.now().isoformat(),
                "analysis": analysis
            })

            return {
                "success": True,
                "response": response,
                "model": self.config["model"]["name"] + " (Enhanced)",
                "history": conversation_history,
                "ai_powered": real_response is not None,
                "analysis": analysis
            }

        except Exception as e:
            logger.error(f"Error processing message: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "response": "‚ö†Ô∏è An error occurred while processing your message. Please try again."
            }

    def process_message_simplified(self, message, conversation_history=None):
        """Simplified intelligent message processor - no rigid categories"""
        try:
            if conversation_history is None:
                conversation_history = []
            
            # Add user message to history
            conversation_history.append({
                "role": "user",
                "content": message,
                "timestamp": datetime.now().isoformat()
            })

            # Build smart context from conversation history
            context_messages = conversation_history[-5:]  # Last 5 messages
            conversation_context = "\n".join([
                f"{msg.get('role', 'user')}: {msg.get('content', '')}"
                for msg in context_messages
            ])

            # Intelligent AI response with full context awareness
            context = f"""You are Chronex AI, an intelligent and helpful assistant by DEMON ALEX.
You have knowledge in programming, mathematics, data science, and general conversation.
Be natural, friendly, and adapt to the user's needs.

Recent conversation:
{conversation_context}"""

            response = self.get_ai_response(message, context)
            
            if not response:
                # Fallback with helpful generic response
                response = """üí≠ I'm here to help! Feel free to ask me about:
- Programming and code help
- Math and calculations
- Data science questions  
- General advice and conversation
- And much more!

What would you like to discuss?"""

            # Add to history
            conversation_history.append({
                "role": "assistant",
                "content": response,
                "timestamp": datetime.now().isoformat()
            })

            return {
                "success": True,
                "response": response,
                "model": self.config["model"]["name"],
                "history": conversation_history
            }

        except Exception as e:
            logger.error(f"Message processing error: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "response": "Sorry, I encountered an issue. Please try again."
            }

    def detect_message_type(self, message):
        """Detect message type for analytics (no longer used for routing)"""
        msg_lower = message.lower()
        if any(x in msg_lower for x in ["?", "what", "how", "why", "explain"]):
            return "question"
        elif any(x in msg_lower for x in ["code", "function", "javascript", "python"]):
            return "technical"
        elif any(x in msg_lower for x in ["hello", "hi", "hey", "greetings"]):
            return "greeting"
        else:
            return "general"

    def handle_creator_query(self, message):
        """Handle creator information queries"""
        creator_responses = [
            f"""üë®‚Äçüíª **Creator Information**\n\nChronex AI was built by:\n\n**Primary Creator:** {CREATOR}\n**Secondary Creator:** {SECONDARY_CREATOR}\n\n**System:** Chronex AI Python Backend\n**Version:** 1.0\n**Created:** {datetime.now().strftime('%Y')}\n\n‚ú® Built with passion for advanced AI solutions!""",
            
            f"""üéØ **About the Creators**\n\n**DEMON ALEX**\n‚Ä¢ Lead Developer\n‚Ä¢ Python Backend Architecture\n‚Ä¢ AI System Design\n\n**DEVELOPER OF NEXCHAT**\n‚Ä¢ Platform Architect\n‚Ä¢ Integration Lead\n‚Ä¢ Full-Stack Implementation\n\nüöÄ Together creating Chronex AI!""",
            
            f"""üèÜ **Creator Profile**\n\n**Names:**\n‚Ä¢ {CREATOR}\n‚Ä¢ {SECONDARY_CREATOR}\n\n**Project:** Chronex AI (Python 4B Model)\n**Specialties:**\n‚Ä¢ Advanced AI systems\n‚Ä¢ Backend architecture\n‚Ä¢ Real-time processing\n\nüí™ Passionate developers!""",
            
            f"""üìã **Development Team**\n\n**Chronex AI System**\n\nCreated by:\n‚úì {CREATOR}\n‚úì {SECONDARY_CREATOR}\n\n**Capabilities:**\n‚Ä¢ Code analysis\n‚Ä¢ Math solving\n‚Ä¢ Data science support\n‚Ä¢ Web development help\n\nüåü Advanced AI assistance!""",
        ]
        
        # Store query in library
        creator_library.add_query(message, "creator")
        
        return def_random(creator_responses)

    def get_advanced_help(self, message):
        """Provide advanced technical assistance"""
        advanced_responses = [
            """üî¨ **Advanced Technical Support**\n\nI can assist with complex scenarios:\n‚Ä¢ Architecture design patterns\n‚Ä¢ Performance optimization techniques\n‚Ä¢ Distributed systems concepts\n‚Ä¢ Concurrency & parallelism\n‚Ä¢ System reliability engineering\n\n**Detailed approach:**\n1. Problem analysis\n2. Multiple solutions\n3. Trade-offs discussion\n4. Implementation guidance""",
            
            """üèóÔ∏è **System Architecture**\n\nBuild robust systems:\n‚Ä¢ Microservices architecture\n‚Ä¢ Event-driven systems\n‚Ä¢ CQRS patterns\n‚Ä¢ Domain-driven design\n‚Ä¢ Service mesh implementation\n\n**Architecture workflow:**\n1. Requirements gathering\n2. Pattern selection\n3. Design documentation\n4. Implementation strategy""",
            
            """‚öôÔ∏è **DevOps & Infrastructure**\n\nAutomate your operations:\n‚Ä¢ CI/CD pipeline design\n‚Ä¢ Container orchestration\n‚Ä¢ Infrastructure as code\n‚Ä¢ Monitoring & logging\n‚Ä¢ Disaster recovery\n\n**Infrastructure approach:**\n1. Current state analysis\n2. Tool selection\n3. Implementation plan\n4. Optimization\"""",
        ]
        return def_random(advanced_responses)

    def check_status(self, message):
        """Check system status when user asks"""
        import psutil
        
        try:
            # Get system info
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            
            status_responses = [
                f"""‚úÖ **System Status Check**\n\n**Chronex AI Status:**\n‚Ä¢ Status: ONLINE üü¢\n‚Ä¢ Model: {CHRONEX_CONFIG['model']['name']}\n‚Ä¢ Version: 1.0\n‚Ä¢ CPU Usage: {cpu_percent}%\n‚Ä¢ Memory Usage: {memory.percent}%\n\n**Services:**\n‚úì Python Backend: Running\n‚úì Flask Server: Active\n‚úì Creator Library: Initialized\n‚úì Response Engine: Ready\n\nüöÄ All systems operational!""",
                
                f"""üîç **Health Check Results**\n\n**System Status:**\n‚Ä¢ Overall: HEALTHY üíö\n‚Ä¢ Uptime: Running\n‚Ä¢ CPU: {cpu_percent}% utilization\n‚Ä¢ Memory: {memory.percent}% in use\n\n**Components:**\n‚úì AI Engine: ‚úÖ Ready\n‚úì API Endpoints: ‚úÖ Live\n‚úì Data Storage: ‚úÖ Active\n‚úì Library System: ‚úÖ Loaded\n\n‚ö° Performance: Excellent""",
                
                f"""üìä **Performance Metrics**\n\n**Current Status:**\n‚Ä¢ State: ONLINE üü¢\n‚Ä¢ Response: {CHRONEX_CONFIG['model']['name']}\n‚Ä¢ CPU Load: {cpu_percent}%\n‚Ä¢ RAM: {memory.percent}%\n\n**Services Running:**\n‚úì Chronex AI Service\n‚úì REST API\n‚úì Creator Library\n‚úì Message Processor\n\nüéØ Ready to assist!""",
                
                f"""üü¢ **Live Status**\n\n**Chronex AI Python Backend**\n‚Ä¢ Status: ACTIVE\n‚Ä¢ CPU: {cpu_percent}%\n‚Ä¢ Memory: {memory.percent}%\n‚Ä¢ Model: 4B Parameters\n\n**Active Services:**\n‚úì Chat Engine\n‚úì Code Analyzer  \n‚úì Math Solver\n‚úì Data Science Tools\n\n‚ú® System fully operational!"""
            ]
            
            # Store status query in library
            creator_library.add_query(message, "status")
            
            return def_random(status_responses)
        except ImportError:
            # Fallback if psutil not available
            fallback = f"""‚úÖ **System Status**\n\n**Chronex AI Status:**\n‚Ä¢ Status: ONLINE üü¢\n‚Ä¢ Model: {CHRONEX_CONFIG['model']['name']}\n‚Ä¢ Version: 1.0\n‚Ä¢ Python Backend: Active\n\n**Services:**\n‚úì Flask API: Running\n‚úì Creator Library: Initialized\n‚úì AI Engine: Ready\n‚úì All endpoints: Live\n\nüöÄ Everything is working perfectly!"""
            return fallback

    def get_data_science_help(self, message):
        """Provide data science and ML guidance"""
        ds_responses = [
            """üìä **Data Science Solutions**\n\nAnalyze and visualize data:\n‚Ä¢ Exploratory data analysis\n‚Ä¢ Statistical modeling\n‚Ä¢ Data visualization\n‚Ä¢ Feature engineering\n‚Ä¢ Data preprocessing\n\n**Data workflow:**\n1. Data collection\n2. Exploratory analysis\n3. Model building\n4. Validation & testing""",
            
            """ü§ñ **Machine Learning Guidance**\n\nBuild intelligent systems:\n‚Ä¢ Supervised learning\n‚Ä¢ Unsupervised learning\n‚Ä¢ Deep learning basics\n‚Ä¢ Model evaluation\n‚Ä¢ Hyperparameter tuning\n\n**ML process:**\n1. Problem definition\n2. Model selection\n3. Training & testing\n4. Deployment strategy""",
            
            """üìà **Predictive Analytics**\n\nForecasting & insights:\n‚Ä¢ Time series analysis\n‚Ä¢ Regression models\n‚Ä¢ Classification algorithms\n‚Ä¢ Anomaly detection\n‚Ä¢ Trend analysis\n\n**Analytics approach:**\n1. Data exploration\n2. Model development\n3. Validation\n4. Interpretation\"""",
        ]
        return def_random(ds_responses)

    def get_web_dev_help(self, message):
        """Provide web development assistance"""
        web_responses = [
            """üåê **Web Development**\n\nBuild modern web applications:\n‚Ä¢ Frontend frameworks\n‚Ä¢ Backend services\n‚Ä¢ Database design\n‚Ä¢ API development\n‚Ä¢ Authentication & security\n\n**Development process:**\n1. Requirements analysis\n2. Architecture design\n3. Implementation\n4. Testing & deployment""",
            
            """‚ö° **Performance Optimization**\n\nSpeed up your applications:\n‚Ä¢ Code optimization\n‚Ä¢ Caching strategies\n‚Ä¢ Asset minification\n‚Ä¢ Database indexing\n‚Ä¢ Load balancing\n\n**Optimization steps:**\n1. Profiling\n2. Bottleneck identification\n3. Solution implementation\n4. Performance validation""",
            
            """üîê **Web Security**\n\nSecure your applications:\n‚Ä¢ OWASP top 10\n‚Ä¢ Input validation\n‚Ä¢ XSS prevention\n‚Ä¢ CSRF protection\n‚Ä¢ SQL injection prevention\n\n**Security process:**\n1. Vulnerability assessment\n2. Risk evaluation\n3. Solution implementation\n4. Testing & verification\"""",
        ]
        return def_random(web_responses)

    def analyze_code(self, message):
        """Analyze code snippets with extensive varied responses"""
        # Detect programming language
        languages = self.config["capabilities"]["language_support"]
        detected_lang = None
        for lang in languages:
            if lang.lower() in message.lower():
                detected_lang = lang
                break

        lang_hint = f'**Language:** {detected_lang}\n\n' if detected_lang else ''
        
        analyses = [
            f"""üìù **Code Review (Python)**\n\n{lang_hint}**Quality Check:**\n‚Ä¢ Structure and organization\n‚Ä¢ Error handling coverage\n‚Ä¢ Performance optimization\n‚Ä¢ Security considerations\n\n**Best Practices:**\n‚úì Add docstrings\n‚úì Use meaningful variable names\n‚úì Implement logging\n‚úì Write unit tests""",
            
            f"""üîç **Code Analysis Report**\n\n{lang_hint}**Insights:**\n‚Ä¢ Code readability: Excellent\n‚Ä¢ Modularity review\n‚Ä¢ Performance metrics\n‚Ä¢ Dependency check\n\n**Recommendations:**\n‚úì Refactor complex functions\n‚úì Add type hints\n‚úì Increase test coverage\n‚úì Document edge cases""",
            
            f"""üíª **Development Analysis**\n\n{lang_hint}**Technical Review:**\n‚Ä¢ Syntax validation: ‚úÖ Passed\n‚Ä¢ Logic flow assessment\n‚Ä¢ Resource efficiency\n‚Ä¢ Code standards compliance\n\n**Suggestions:**\n‚úì Use design patterns\n‚úì Implement error handlers\n‚úì Add CI/CD tests\n‚úì Follow conventions""",
            
            f"""‚úÖ **Code Quality Assessment**\n\n{lang_hint}**Findings:**\n‚Ä¢ Overall structure: Good\n‚Ä¢ Optimization opportunities\n‚Ä¢ Documentation level\n‚Ä¢ Test coverage status\n\n**Action Items:**\n‚úì Simplify complex logic\n‚úì Add comments\n‚úì Use constants for magic numbers\n‚úì Improve error messages""",
            
            f"""üéØ **Advanced Code Inspection**\n\n{lang_hint}**Deep Dive Analysis:**\n‚Ä¢ Memory efficiency review\n‚Ä¢ Concurrency handling\n‚Ä¢ Exception management\n‚Ä¢ API design patterns\n\n**Enhancement Ideas:**\n‚úì Implement caching mechanisms\n‚úì Add async/await patterns\n‚úì Use dependency injection\n‚úì Apply SOLID principles""",
            
            f"""üîß **Code Optimization Report**\n\n{lang_hint}**Performance Audit:**\n‚Ä¢ Algorithm complexity (Big O)\n‚Ä¢ Database query optimization\n‚Ä¢ Network latency considerations\n‚Ä¢ CPU & memory profiling\n\n**Optimization Strategies:**\n‚úì Use efficient data structures\n‚úì Implement lazy loading\n‚úì Add memoization\n‚úì Reduce cyclomatic complexity""",
            
            f"""üõ°Ô∏è **Security Analysis**\n\n{lang_hint}**Security Findings:**\n‚Ä¢ Input validation checks\n‚Ä¢ SQL injection prevention\n‚Ä¢ Authentication/authorization\n‚Ä¢ Data encryption status\n\n**Security Enhancements:**\n‚úì Validate all inputs\n‚úì Use prepared statements\n‚úì Implement rate limiting\n‚úì Add security headers""",
            
            f"""üìà **Code Maintainability Review**\n\n{lang_hint}**Maintainability Metrics:**\n‚Ä¢ Coupling & cohesion levels\n‚Ä¢ Code duplication detection\n‚Ä¢ Naming convention consistency\n‚Ä¢ Documentation completeness\n\n**Improvements:**\n‚úì Extract common functions\n‚úì Improve variable names\n‚úì Add inline documentation\n‚úì Create architectural diagrams""",
            
            f"""üöÄ **Performance & Scalability**\n\n{lang_hint}**Scalability Assessment:**\n‚Ä¢ Horizontal scaling readiness\n‚Ä¢ Load balancing compatibility\n‚Ä¢ Database scaling options\n‚Ä¢ Microservices potential\n\n**Scaling Recommendations:**\n‚úì Implement caching layer\n‚úì Add message queues\n‚úì Use CDN for static assets\n‚úì Database sharding strategy""",
            
            f"""üß™ **Testing & Reliability**\n\n{lang_hint}**Test Coverage Analysis:**\n‚Ä¢ Unit test coverage percentage\n‚Ä¢ Integration test presence\n‚Ä¢ End-to-end test scenarios\n‚Ä¢ Error handling robustness\n\n**Testing Improvements:**\n‚úì Add missing unit tests\n‚úì Implement integration tests\n‚úì Create smoke tests\n‚úì Add regression tests"""
        ]
        
        return def_random(analyses)

    def solve_math(self, message):
        """Solve mathematical problems with extensive varied responses"""
        math_responses = [
            """üî¢ **Mathematical Solution**\n\nI can help solve:\n‚Ä¢ Algebra problems\n‚Ä¢ Calculus derivatives and integrals\n‚Ä¢ Linear equations systems\n‚Ä¢ Statistics and probability\n‚Ä¢ Geometry problems\n\n**Step-by-step approach:**\n1. Identify the problem type\n2. Apply relevant formulas\n3. Show all working\n4. Verify the solution""",
            
            """üìê **Mathematics Assistance**\n\nShare your problem and I'll work through it!\n‚Ä¢ Equations & expressions\n‚Ä¢ Calculus (limits, derivatives)\n‚Ä¢ Probability distributions\n‚Ä¢ Matrix operations\n‚Ä¢ Geometric proofs\n\n**My process:**\n1. Analyze the problem\n2. Select best method\n3. Detailed solutions\n4. Answer verification""",
            
            """üßÆ **Let's Solve This!**\n\nReady to tackle your math challenge:\n‚Ä¢ Pre-algebra to advanced math\n‚Ä¢ Real-world applications\n‚Ä¢ Formula derivations\n‚Ä¢ Complex calculations\n‚Ä¢ Problem explanations\n\n**What I provide:**\n1. Complete breakdown\n2. Step-by-step work\n3. Final answer\n4. Alternative methods""",
            
            """üéØ **Math Problem Solver**\n\nLet's find your solution!\n‚Ä¢ Pure mathematics\n‚Ä¢ Applied mathematics\n‚Ä¢ Numerical analysis\n‚Ä¢ Mathematical modeling\n‚Ä¢ Optimization problems\n\n**Solution path:**\n1. Problem assessment\n2. Method selection\n3. Detailed computation\n4. Solution validation""",
            
            """‚àë **Calculus & Advanced Math**\n\nTackle complex mathematical challenges:\n‚Ä¢ Differential equations\n‚Ä¢ Multivariable calculus\n‚Ä¢ Fourier analysis\n‚Ä¢ Differential geometry\n‚Ä¢ Complex number operations\n\n**Comprehensive approach:**\n1. Problem classification\n2. Theorem application\n3. Numerical computation\n4. Result interpretation""",
            
            """üìä **Statistics & Probability**\n\nAnalyze data and uncertainty:\n‚Ä¢ Probability distributions\n‚Ä¢ Statistical inference\n‚Ä¢ Hypothesis testing\n‚Ä¢ Regression analysis\n‚Ä¢ Time series analysis\n\n**Statistical workflow:**\n1. Data examination\n2. Assumption testing\n3. Method selection\n4. Conclusion drawing""",
            
            """üî¢ **Number Theory & Algebra**\n\nExplore mathematical structures:\n‚Ä¢ Prime factorization\n‚Ä¢ Modular arithmetic\n‚Ä¢ Polynomial operations\n‚Ä¢ Matrix algebra\n‚Ä¢ Abstract algebra concepts\n\n**Solution methodology:**\n1. Problem breakdown\n2. Technique selection\n3. Detailed computation\n4. Answer validation""",
            
            """üìè **Geometry & Trigonometry**\n\nSolve spatial and angular problems:\n‚Ä¢ Coordinate geometry\n‚Ä¢ 3D transformations\n‚Ä¢ Trigonometric identities\n‚Ä¢ Vector operations\n‚Ä¢ Geometric proofs\n\n**Geometric approach:**\n1. Visualization setup\n2. Formula application\n3. Step-by-step solving\n4. Result verification""",
            
            """üéì **Advanced Problem Solving**\n\nTake on complex mathematical challenges:\n‚Ä¢ Multi-step problems\n‚Ä¢ Proof techniques\n‚Ä¢ Mathematical optimization\n‚Ä¢ Applied mathematics\n‚Ä¢ Engineering mathematics\n\n**Advanced methodology:**\n1. Problem deconstruction\n2. Strategy development\n3. Implementation\n4. Thorough verification""",
            
            """üí° **Mathematical Insights**\n\nGain deeper mathematical understanding:\n‚Ä¢ Conceptual foundations\n‚Ä¢ Formula derivations\n‚Ä¢ Proof explanations\n‚Ä¢ Historical context\n‚Ä¢ Real-world applications\n\n**Educational approach:**\n1. Concept introduction\n2. Formula development\n3. Example walkthroughs\n4. Practice problems"""
        ]
        return def_random(math_responses)

    def answer_question(self, message):
        """Answer general questions with extensive varied responses"""
        question_responses = [
            """‚ùì **Detailed Answer**\n\nI can help you understand by:\n‚Ä¢ Breaking down concepts\n‚Ä¢ Providing examples\n‚Ä¢ Explaining step-by-step\n‚Ä¢ Offering resources\n\n**What I offer:**\n‚Ä¢ Technical depth\n‚Ä¢ Practical applications\n‚Ä¢ Multiple perspectives\n‚Ä¢ Learning resources""",
            
            """ü§î **Let's Explore This**\n\nGreat question! Here's what I provide:\n‚Ä¢ Clear explanations\n‚Ä¢ Real-world examples\n‚Ä¢ In-depth analysis\n‚Ä¢ Reference materials\n\n**I can help with:**\n‚Ä¢ Concept clarification\n‚Ä¢ Detailed breakdowns\n‚Ä¢ Visual explanations\n‚Ä¢ Further resources""",
            
            """üí° **Insight & Explanation**\n\nExcellent thinking! I'll help you understand:\n‚Ä¢ Core concepts\n‚Ä¢ Practical examples\n‚Ä¢ Advanced details\n‚Ä¢ Related topics\n\n**My approach:**\n‚Ä¢ Simple to complex\n‚Ä¢ Theory + practice\n‚Ä¢ Multiple examples\n‚Ä¢ External references""",
            
            """üéì **Question Response**\n\nFantastic question! Let me explain:\n‚Ä¢ Comprehensive answer\n‚Ä¢ Real examples\n‚Ä¢ Step-by-step guide\n‚Ä¢ Knowledge resources\n\n**I provide:**\n‚Ä¢ Deep explanations\n‚Ä¢ Concrete examples\n‚Ä¢ Visual aids\n‚Ä¢ Learning materials""",
            
            """üî¨ **Scientific Explanation**\n\nLet's dive into the science:\n‚Ä¢ Evidence-based answers\n‚Ä¢ Research findings\n‚Ä¢ Theoretical foundations\n‚Ä¢ Experimental validation\n\n**Scientific method:**\n1. Literature review\n2. Theory explanation\n3. Evidence presentation\n4. Conclusion summary""",
            
            """üìö **Educational Deep Dive**\n\nComprehensive learning resource:\n‚Ä¢ Curriculum-aligned content\n‚Ä¢ Progressive complexity\n‚Ä¢ Multiple learning styles\n‚Ä¢ Interactive examples\n\n**Learning pathway:**\n1. Foundation concepts\n2. Intermediate understanding\n3. Advanced topics\n4. Application exercises""",
            
            """üéØ **Practical Guidance**\n\nReal-world application focus:\n‚Ä¢ How-to instructions\n‚Ä¢ Best practices\n‚Ä¢ Common pitfalls\n‚Ä¢ Success strategies\n\n**Practical approach:**\n1. Situation analysis\n2. Strategy development\n3. Implementation steps\n4. Results evaluation""",
            
            """üß† **Cognitive Explanation**\n\nMake complex ideas simple:\n‚Ä¢ Analogies and metaphors\n‚Ä¢ Mental models\n‚Ä¢ Conceptual frameworks\n‚Ä¢ Memory aids\n\n**Explanation strategy:**\n1. Familiar connections\n2. Progressive building\n3. Pattern recognition\n4. Skill application""",
            
            """üåê **Comprehensive Overview**\n\nBroad perspective analysis:\n‚Ä¢ Historical context\n‚Ä¢ Current state\n‚Ä¢ Future trends\n‚Ä¢ Global implications\n\n**Holistic approach:**\n1. Background information\n2. Detailed examination\n3. Comparative analysis\n4. Future outlook""",
            
            """‚ö° **Quick & Detailed**\n\nBoth concise and thorough:\n‚Ä¢ Summary overview\n‚Ä¢ Detailed breakdown\n‚Ä¢ Key takeaways\n‚Ä¢ Additional resources\n\n**Flexible delivery:**\n1. Quick summary\n2. Extended explanation\n3. Important highlights\n4. Further learning"""
        ]
        return def_random(question_responses)

    def handle_greeting(self, message):
        """Handle greeting messages with extensive varied responses"""
        greetings = [
            "ü§ñ Hey there! I'm Chronex AI, powered by Python backend! How can I assist you today?",
            "Hello! Welcome to Chronex AI (Python Edition). What would you like to explore?",
            "Greetings! Ready to solve problems? üí°",
            "Hi! I'm Chronex AI. Ask me anything! üöÄ",
            "Welcome! üåü I'm Chronex AI (Python). How may I assist you today?",
            "Yo! üëã Thanks for connecting. What's on your mind?",
            "Hey! üôå I'm Chronex AI. Ready to help with anything!",
            "Sup! ü§ñ What can I do for you today?",
            "Greetings! üëã I'm Chronex AI Python Edition. Let's get started!",
            "Hello there! üíª I'm ready to assist. What do you need?",
            "Welcome aboard! üöÄ I'm Chronex AI. Let's solve something amazing!",
            "Hey buddy! üëä I'm Chronex AI. What's your challenge today?",
            "Howdy! ü§† I'm Chronex AI. Ready to tackle problems?",
            "Salutations! üé© I'm your Chronex AI assistant. How can I help?",
            "Top of the morning! ‚òÄÔ∏è I'm Chronex AI. What'll it be?",
            "Hey there, friend! ü§ù I'm Chronex AI. Let's collaborate!",
            "Greetings, human! üåç I'm Chronex AI. Ready to assist?",
            "Welcome! üéâ I'm Chronex AI. Let's make something great!",
            "Hello, wonderful human! ‚ú® I'm Chronex AI. What's on your agenda?",
            "Heya! üëç I'm Chronex AI. Let's get to work!",
        ]
        return def_random(greetings)

    def generate_general_response(self, message):
        """Generate general response with extensive varied replies"""
        responses = [
            """üí¨ **Response**\n\nI'm Chronex AI with Python backend capabilities:\n\nüîß **Technical Help:**\n‚Ä¢ Code analysis and review\n‚Ä¢ Algorithm optimization\n‚Ä¢ Debugging assistance\n\nüìä **Data & Analysis:**\n‚Ä¢ Data processing\n‚Ä¢ Statistical analysis\n‚Ä¢ Visualization recommendations\n\nWhat would you like to work on?""",
            
            """Thanks for reaching out! üôã I'm equipped to help with:\n‚Ä¢ Software development support\n‚Ä¢ Problem-solving strategies\n‚Ä¢ Research and analysis\n‚Ä¢ Code optimization\n‚Ä¢ Technical explanations\n\nWhat's your need?""",
            
            """Nice to chat! üí≠ I specialize in:\n‚Ä¢ Code review & optimization\n‚Ä¢ Mathematical solutions\n‚Ä¢ In-depth explanations\n‚Ä¢ Data analysis\n‚Ä¢ Technical assistance\n\nWhat shall we work on?""",
            
            """Got you! üëç I can help with:\n‚Ä¢ Python & JavaScript\n‚Ä¢ Complex calculations\n‚Ä¢ Detailed Q&A\n‚Ä¢ Code suggestions\n‚Ä¢ Analytics\n\nWhat's next?""",
            
            """Perfect timing! ‚è∞ My skills include:\n‚Ä¢ Full-stack development support\n‚Ä¢ Advanced mathematics\n‚Ä¢ Comprehensive answers\n‚Ä¢ Code optimization\n‚Ä¢ Information analysis\n\nHow can I assist?""",
            
            """I hear you! üëÇ Here are some things I'm great at:\n‚Ä¢ üíª Code analysis\n‚Ä¢ üìä Data processing\n‚Ä¢ ‚ùì Answering questions\n‚Ä¢ ‚úçÔ∏è Technical writing\n‚Ä¢ üî¢ Math solutions\n\nLet's dive in!""",
            
            """That's interesting! ü§î I can assist you with:\n‚Ä¢ Programming support\n‚Ä¢ Problem-solving\n‚Ä¢ Detailed explanations\n‚Ä¢ Creative solutions\n‚Ä¢ Data insights\n\nHow can I help?""",
            
            """Absolutely! üéØ I'm ready to help with:\n‚Ä¢ System design and architecture\n‚Ä¢ Database optimization\n‚Ä¢ API development\n‚Ä¢ Cloud solutions\n‚Ä¢ DevOps strategies\n\nWhat would you like to tackle?""",
            
            """Excited to help! üåü My expertise covers:\n‚Ä¢ Machine learning basics\n‚Ä¢ Neural network concepts\n‚Ä¢ Data science workflows\n‚Ä¢ AI implementation\n‚Ä¢ Model evaluation\n\nWhat interests you?""",
            
            """Great question! üß† I can support you with:\n‚Ä¢ Algorithm design\n‚Ä¢ Design patterns\n‚Ä¢ Software architecture\n‚Ä¢ Performance tuning\n‚Ä¢ Code refactoring\n\nLet's improve your code!""",
            
            """Fantastic! üöÄ I'm here for:\n‚Ä¢ Building scalable systems\n‚Ä¢ Cloud architecture\n‚Ä¢ Microservices design\n‚Ä¢ DevOps practices\n‚Ä¢ Infrastructure as code\n\nReady to scale?""",
            
            """You got it! ‚úÖ Let's work on:\n‚Ä¢ Web application development\n‚Ä¢ Mobile app solutions\n‚Ä¢ API integration\n‚Ä¢ Database design\n‚Ä¢ Frontend optimization\n\nWhat's your project?""",
            
            """Absolutely! üí™ I specialize in:\n‚Ä¢ Security implementations\n‚Ä¢ Authentication systems\n‚Ä¢ Encryption methods\n‚Ä¢ Vulnerability assessment\n‚Ä¢ Compliance guidance\n\nLet's secure your system!""",
            
            """Perfect! üé® I can help with:\n‚Ä¢ User interface optimization\n‚Ä¢ User experience improvement\n‚Ä¢ Performance enhancement\n‚Ä¢ Accessibility standards\n‚Ä¢ Design patterns\n\nWhat needs improvement?""",
            
            """Let's go! üî• I'm equipped for:\n‚Ä¢ Testing strategies\n‚Ä¢ Test automation\n‚Ä¢ Quality assurance\n‚Ä¢ Debugging techniques\n‚Ä¢ Error handling\n\nWhat shall we test?""",
            
            """Bring it on! üíØ My capabilities include:\n‚Ä¢ Documentation writing\n‚Ä¢ Technical specification\n‚Ä¢ API documentation\n‚Ä¢ Code commenting\n‚Ä¢ Knowledge base creation\n\nWhat needs documenting?""",
        ]
        return def_random(responses)

    def handle_image_query(self, message):
        """Handle image-related queries"""
        image_responses = [
            """üì∏ **Image Processing Module**

I can help you with image analysis! Here are your options:

üîÑ **Available Actions:**
1. **Upload Image**: POST `/ai/upload-image` with image file
2. **Scan & Analyze**: POST `/ai/scan-image` to upload and analyze
3. **AI Vision**: POST `/ai/image-vision` for detailed analysis with questions
4. **List Images**: GET `/ai/image-list` to see uploaded images
5. **Delete Image**: DELETE `/ai/image-delete/<filename>`

ü§ñ **Capabilities:**
‚Ä¢ Object detection and recognition
‚Ä¢ OCR (Optical Character Recognition)
‚Ä¢ Scene understanding
‚Ä¢ Text extraction from images
‚Ä¢ Detailed image descriptions

üìù **Note:** Advanced AI analysis requires OpenAI API key (GPT-4 Vision)

Ready to analyze an image? Upload one and I'll scan it for you! üöÄ""",
            
            """üñºÔ∏è **Image Analysis Ready!**

I have image processing capabilities:

**Upload Endpoint:**
```
POST /ai/upload-image
Content-Type: multipart/form-data
Form field: "image" (your image file)
```

**Scan & Analyze:**
```
POST /ai/scan-image
Content-Type: multipart/form-data
Form field: "image" (your image file)
```

**AI Vision Query:**
```
POST /ai/image-vision
{
  "filepath": "uploads/images/filename.jpg",
  "question": "Your custom question about the image"
}
```

Supported formats: PNG, JPG, JPEG, GIF, WEBP, BMP
Max file size: 10MB

What would you like to analyze? üì∑""",
            
            """üéØ **Image Recognition System**

You asked about images! I can:

‚úÖ **Scan Images** - Upload images for analysis
‚úÖ **Detect Objects** - Identify what's in your images
‚úÖ **Read Text** - Extract text from images (OCR)
‚úÖ **Analyze Scenes** - Understand image composition
‚úÖ **Answer Questions** - Ask specific questions about images

**Quick Start:**
1. Send an image file to `/ai/scan-image`
2. I'll analyze it using AI vision
3. Get detailed results and descriptions

**Requirements:**
- Image file (PNG, JPG, GIF, WebP, BMP)
- Size: Under 10MB

Have an image ready? Upload it! üöÄüì∏""",
            
            """üîç **Image Scanning & Analysis**

Perfect question! I support:

üì∑ **Image Upload**: Store images securely
ü§ñ **AI Analysis**: GPT-4 Vision for detailed understanding
üìù **Text Recognition**: OCR capabilities
üé® **Visual Understanding**: Colors, shapes, composition
üí¨ **Q&A**: Ask questions about images

**Endpoints Available:**
- `/ai/upload-image` - Upload and store
- `/ai/scan-image` - Upload and immediately analyze
- `/ai/analyze-image` - Analyze pre-uploaded image
- `/ai/image-vision` - Ask custom questions
- `/ai/image-list` - View all images
- `/ai/image-delete` - Remove images

Let's analyze some images! üì∏‚ú®""",
            
            """üé¨ **Vision & Image Processing**

I've got you covered with image capabilities!

**Three Ways to Process:**
1Ô∏è‚É£ **Quick Upload** ‚Üí POST `/ai/upload-image`
2Ô∏è‚É£ **Full Analysis** ‚Üí POST `/ai/scan-image`
3Ô∏è‚É£ **AI Questions** ‚Üí POST `/ai/image-vision`

**What I Can Do:**
‚Ä¢ Describe image contents in detail
‚Ä¢ Identify objects and scenes
‚Ä¢ Extract and read text (OCR)
‚Ä¢ Analyze composition and colors
‚Ä¢ Answer specific questions about images

**Example Response:**
```json
{
  "success": true,
  "analysis": "This image shows...",
  "method": "OpenAI Vision (GPT-4V)",
  "filepath": "uploads/images/..."
}
```

Ready to scan? Upload an image! üöÄüì∏""",
        ]
        return def_random(image_responses)

# Initialize AI
chronex_python = ChronexAIPython(CHRONEX_CONFIG)

# ============ API ENDPOINTS ============

@app.route('/ai/advanced-help', methods=['POST'])
def advanced_help():
    """Advanced technical assistance endpoint"""
    try:
        data = request.get_json()
        message = data.get('message', '')

        response = chronex_python.get_advanced_help(message)
        return jsonify({
            "success": True,
            "response": response,
            "type": "advanced"
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/ai/data-science', methods=['POST'])
def data_science_help():
    """Data science and ML guidance endpoint"""
    try:
        data = request.get_json()
        message = data.get('message', '')

        response = chronex_python.get_data_science_help(message)
        return jsonify({
            "success": True,
            "response": response,
            "type": "data-science"
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/ai/web-dev', methods=['POST'])
def web_dev_help():
    """Web development assistance endpoint"""
    try:
        data = request.get_json()
        message = data.get('message', '')

        response = chronex_python.get_web_dev_help(message)
        return jsonify({
            "success": True,
            "response": response,
            "type": "web-dev"
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/ai/capabilities', methods=['GET'])
def get_capabilities():
    """Get full AI capabilities"""
    capabilities = {
        "general": ["chat", "code analysis", "math solving", "question answering"],
        "advanced": ["system architecture", "devops", "infrastructure"],
        "data_science": ["data analysis", "machine learning", "predictive analytics"],
        "web_dev": ["web development", "performance optimization", "security"],
        "supported_languages": CHRONEX_CONFIG["capabilities"]["language_support"]
    }
    return jsonify({"success": True, "capabilities": capabilities})

@app.route('/ai/health', methods=['GET'])
def health_check():
    """Detailed health check"""
    return jsonify({
        "status": "healthy",
        "uptime": "running",
        "model": CHRONEX_CONFIG["model"]["name"],
        "capabilities": list(CHRONEX_CONFIG["capabilities"].keys()),
        "version": "1.0",
        "python_backend": True
    })

@app.route('/ai/model-info', methods=['GET'])
def model_info():
    """Get detailed model information"""
    return jsonify({
        "model_name": CHRONEX_CONFIG["model"]["name"],
        "parameters": CHRONEX_CONFIG["parameters"],
        "model_config": CHRONEX_CONFIG["model"],
        "creator": CHRONEX_CONFIG["creator"],
        "version": "1.0"
    })

# ============ CREATOR LIBRARY ENDPOINTS ============

@app.route('/ai/creator-info', methods=['GET'])
def get_creator_full_info():
    """Get full creator information and library stats"""
    try:
        info = creator_library.get_creator_info()
        return jsonify({
            "success": True,
            "creator_info": info,
            "primary": CREATOR,
            "secondary": SECONDARY_CREATOR
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/ai/creator-library', methods=['GET'])
def get_creator_library():
    """Get entire creator library export"""
    try:
        library = creator_library.export_library()
        return jsonify({
            "success": True,
            "library": library
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/ai/creator-library/query-history', methods=['GET'])
def get_query_history():
    """Get creator query history"""
    try:
        limit = request.args.get('limit', 10, type=int)
        history = creator_library.get_query_history(limit)
        return jsonify({
            "success": True,
            "total_queries": len(creator_library.creator_data["query_history"]),
            "recent_queries": history
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/ai/creator-library/store', methods=['POST'])
def store_creator_info():
    """Store custom information in creator library"""
    try:
        data = request.get_json()
        key = data.get('key')
        value = data.get('value')
        
        if not key or not value:
            return jsonify({"error": "Key and value required"}), 400
        
        creator_library.store_info(key, value)
        return jsonify({
            "success": True,
            "message": f"Stored '{key}' in creator library",
            "stored_items": len(creator_library.creator_data["stored_info"])
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/ai/creator-library/retrieve/<key>', methods=['GET'])
def retrieve_creator_info(key):
    """Retrieve specific information from creator library"""
    try:
        info = creator_library.get_stored_info(key)
        if not info:
            return jsonify({"error": f"No information found for key '{key}'"}), 404
        
        return jsonify({
            "success": True,
            "key": key,
            "data": info
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/ai/creator-library/clear-history', methods=['POST'])
def clear_query_history():
    """Clear creator query history"""
    try:
        creator_library.clear_history()
        return jsonify({
            "success": True,
            "message": "Query history cleared"
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/ai/creator', methods=['GET'])
def get_creator():
    """Get creator information"""
    return jsonify(creator())

# ============ REAL AI CONFIG ENDPOINTS ============

@app.route('/ai/config', methods=['GET'])
def get_ai_config():
    """Get current AI configuration"""
    return jsonify({
        "success": True,
        "ai_provider": config_manager.get("ai_provider"),
        "use_real_ai": config_manager.get("use_real_ai"),
        "openai_available": OPENAI_AVAILABLE,
        "huggingface_available": HUGGINGFACE_AVAILABLE,
        "dotenv_available": DOTENV_AVAILABLE,
        "models": {
            "openai": config_manager.get("openai_model"),
            "huggingface": config_manager.get("huggingface_model"),
        }
    })

@app.route('/ai/config/update', methods=['POST'])
def update_ai_config():
    """Update AI configuration"""
    try:
        data = request.get_json()
        
        for key, value in data.items():
            config_manager.set(key, value)
            logger.info(f"‚úÖ Config updated: {key} = {value}")
        
        return jsonify({
            "success": True,
            "message": "Configuration updated",
            "config": config_manager.config
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/ai/providers', methods=['GET'])
def get_providers():
    """Get available AI providers"""
    return jsonify({
        "success": True,
        "available_providers": {
            "openai": OPENAI_AVAILABLE,
            "huggingface": HUGGINGFACE_AVAILABLE,
            "ollama": True,  # Always available if server running
            "default": True
        },
        "current_provider": config_manager.get("ai_provider")
    })

@app.route('/ai/chat', methods=['POST'])
def chat():
    """Main chat endpoint - uses intelligent context-aware responses"""
    try:
        data = request.get_json()
        message = data.get('message', '')
        history = data.get('history', [])

        if not message:
            return jsonify({"error": "No message provided"}), 400

        # Use the new simplified intelligent processor
        result = chronex_python.process_message_simplified(message, history)
        return jsonify(result)

    except Exception as e:
        logger.error(f"Chat endpoint error: {str(e)}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/ai/analyze-code', methods=['POST'])
def analyze_code():
    """Dedicated code analysis endpoint"""
    try:
        data = request.get_json()
        code = data.get('code', '')
        language = data.get('language', 'unknown')

        response = chronex_python.analyze_code(f"Analyze this {language} code")
        return jsonify({
            "success": True,
            "analysis": response,
            "language": language
        })

    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/ai/solve-math', methods=['POST'])
def solve_math():
    """Math solving endpoint"""
    try:
        data = request.get_json()
        problem = data.get('problem', '')

        response = chronex_python.solve_math(problem)
        return jsonify({
            "success": True,
            "solution": response
        })

    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/ai/status', methods=['GET'])
def status():
    """Health check endpoint"""
    return jsonify({
        "status": "online",
        "model": CHRONEX_CONFIG["model"]["name"],
        "version": "1.0",
        "capabilities": list(CHRONEX_CONFIG["capabilities"].keys())
    })

@app.route('/ai/reset', methods=['POST'])
def reset():
    """Reset conversation history"""
    chronex_python.conversation_history = []
    return jsonify({"success": True, "message": "Conversation history cleared"})

# ============ IMAGE PROCESSING ENDPOINTS ============

@app.route('/ai/upload-image', methods=['POST'])
def upload_image():
    """Upload and process image"""
    try:
        # Check if file is in request
        if 'image' not in request.files:
            return jsonify({"error": "No image file provided"}), 400
        
        file = request.files['image']
        if file.filename == '':
            return jsonify({"error": "No image selected"}), 400
        
        # Save image
        filepath, status = image_processor.save_image(file)
        if not filepath:
            return jsonify({"error": status}), 400
        
        logger.info(f"‚úÖ Image uploaded: {file.filename}")
        
        return jsonify({
            "success": True,
            "message": "Image uploaded successfully",
            "filename": file.filename,
            "filepath": filepath,
            "timestamp": datetime.now().isoformat()
        })
    except Exception as e:
        logger.error(f"‚ùå Upload error: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/ai/analyze-image', methods=['POST'])
def analyze_image():
    """Analyze uploaded image"""
    try:
        data = request.get_json() or {}
        filepath = data.get('filepath')
        use_ai = data.get('use_ai', True)
        
        if not filepath or not os.path.exists(filepath):
            return jsonify({"error": "Image file not found"}), 404
        
        # Try OpenAI Vision first if enabled
        if use_ai and OPENAI_AVAILABLE and config_manager.get("enable_vision"):
            analysis = image_processor.analyze_image_openai(filepath)
            if analysis:
                return jsonify({
                    "success": True,
                    "analysis": analysis,
                    "method": "OpenAI Vision (GPT-4V)",
                    "filepath": filepath
                })
        
        # Fallback to basic PIL analysis
        analysis = image_processor.analyze_image_basic(filepath)
        if analysis:
            return jsonify({
                "success": True,
                "analysis": analysis,
                "method": "Basic Analysis (PIL)",
                "filepath": filepath,
                "note": "For advanced AI analysis, set up OpenAI API key"
            })
        
        return jsonify({"error": "Could not analyze image"}), 500
        
    except Exception as e:
        logger.error(f"‚ùå Analysis error: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/ai/scan-image', methods=['POST'])
def scan_image():
    """Scan image (OCR + Analysis)"""
    try:
        # Check for file in form data
        if 'image' not in request.files:
            return jsonify({"error": "No image file provided"}), 400
        
        file = request.files['image']
        if file.filename == '':
            return jsonify({"error": "No image selected"}), 400
        
        # Save image
        filepath, status = image_processor.save_image(file)
        if not filepath:
            return jsonify({"error": status}), 400
        
        # Analyze image
        analysis = None
        method = "None"
        
        # Try OpenAI Vision first
        if OPENAI_AVAILABLE and config_manager.get("enable_vision"):
            try:
                analysis = image_processor.analyze_image_openai(filepath)
                method = "OpenAI Vision (GPT-4V)"
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è OpenAI analysis failed: {e}")
        
        # Fallback to basic analysis
        if not analysis:
            analysis = image_processor.analyze_image_basic(filepath)
            method = "Basic Analysis (PIL)"
        
        return jsonify({
            "success": True,
            "message": "Image scanned and analyzed",
            "filename": file.filename,
            "filepath": filepath,
            "analysis": analysis,
            "analysis_method": method,
            "timestamp": datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"‚ùå Scan error: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/ai/image-vision', methods=['POST'])
def image_vision():
    """Advanced image vision API"""
    try:
        data = request.get_json()
        question = data.get('question', 'Describe this image in detail')
        filepath = data.get('filepath')
        
        if not filepath or not os.path.exists(filepath):
            return jsonify({"error": "Image file not found"}), 404
        
        # Use OpenAI Vision with custom question
        if not OPENAI_AVAILABLE:
            return jsonify({"error": "OpenAI not available"}), 503
        
        try:
            base64_image = image_processor.get_image_base64(filepath)
            if not base64_image:
                return jsonify({"error": "Could not encode image"}), 500
            
            response = openai.ChatCompletion.create(
                model="gpt-4-vision-preview",
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": question},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{base64_image}"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=1000
            )
            
            return jsonify({
                "success": True,
                "question": question,
                "response": response.choices[0].message.content,
                "filepath": filepath
            })
        except Exception as e:
            logger.error(f"‚ùå Vision API error: {e}")
            return jsonify({"error": f"Vision API error: {str(e)}"}), 503
        
    except Exception as e:
        logger.error(f"‚ùå Vision endpoint error: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/ai/image-list', methods=['GET'])
def list_images():
    """List all uploaded images"""
    try:
        images = []
        upload_dir = image_processor.upload_dir
        
        if os.path.exists(upload_dir):
            for filename in os.listdir(upload_dir):
                filepath = os.path.join(upload_dir, filename)
                if os.path.isfile(filepath):
                    images.append({
                        "filename": filename,
                        "filepath": filepath,
                        "size": os.path.getsize(filepath),
                        "modified": datetime.fromtimestamp(os.path.getmtime(filepath)).isoformat()
                    })
        
        return jsonify({
            "success": True,
            "total_images": len(images),
            "images": images
        })
    except Exception as e:
        logger.error(f"‚ùå List images error: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/ai/image-delete/<filename>', methods=['DELETE'])
def delete_image(filename):
    """Delete uploaded image"""
    try:
        filepath = os.path.join(image_processor.upload_dir, filename)
        
        if not os.path.exists(filepath):
            return jsonify({"error": "Image not found"}), 404
        
        os.remove(filepath)
        logger.info(f"‚úÖ Image deleted: {filename}")
        
        return jsonify({
            "success": True,
            "message": f"Image '{filename}' deleted"
        })
    except Exception as e:
        logger.error(f"‚ùå Delete error: {e}")
        return jsonify({"error": str(e)}), 500

# ============ ERROR HANDLERS ============

@app.errorhandler(404)
def not_found(error):
    return jsonify({"error": "Endpoint not found"}), 404

@app.errorhandler(500)
def internal_error(error):
    return jsonify({"error": "Internal server error"}), 500

# ============ MAIN ============

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    debug = os.environ.get('DEBUG', 'False').lower() == 'true'
    
    logger.info(f"Starting Chronex AI (Python Backend) on port {port}")
    logger.info(f"Debug mode: {debug}")
    logger.info(f"Model: {CHRONEX_CONFIG['model']['name']}")
    
    app.run(
        host='0.0.0.0',
        port=port,
        debug=debug,
        threaded=True
    )
    
    logger.info("‚ú® Chronex AI (Python Backend) is running on NEXCHAT - The future is initialized!")


def print_info():
    """Print system information and credits"""
    print("\n" + "="*70)
    print("üöÄ NEXCHAT & CHRONEX AI - THE FUTURE IS HERE!")
    print("="*70)
    print("\nüìä System Information:")
    print("   ‚Ä¢ Creator: DEMON ALEX")
    print("   ‚Ä¢ Co-Developer: DEVELOPER OF NEXCHAT")
    print("   ‚Ä¢ System: Chronex AI Python Backend v1.0")
    print("   ‚Ä¢ Model: 4B Parameters Advanced Neural Network")
    print("\nüí° Key Features:")
    print("   ‚úì Advanced AI Chat System")
    print("   ‚úì Code Analysis & Review")
    print("   ‚úì Mathematical Problem Solving")
    print("   ‚úì Data Science Support")
    print("   ‚úì Web Development Assistance")
    print("   ‚úì Creator Library Storage")
    print("   ‚úì Real-time Status Monitoring")
    print("\nüìß For Collaboration & Support:")
    print("   Email: demonalexander526@gmail.com")
    print("   Contact: DEMON ALEX for integration, features, or assistance")
    print("\nüí¨ About Tokens:")
    print("   ‚Ä¢ Tokens reduce spam and maintain database integrity")
    print("   ‚Ä¢ Essential for NEXCHAT's operational efficiency")
    print("   ‚Ä¢ Part of the platform's security architecture")
    print("\nüìù Note:")
    print("   NEXCHAT is actively being developed with continuous improvements.")
    print("   Integration support available through the contact above.")
    print("\n" + "="*70 + "\n")

# Run info on startup
if __name__ == '__main__':
    print_info()
    port = int(os.environ.get('PORT', 5000))
    debug = os.environ.get('DEBUG', 'False').lower() == 'true'
    
    logger.info(f"Starting Chronex AI (Python Backend) on port {port}")
    logger.info(f"Debug mode: {debug}")
    logger.info(f"Model: {CHRONEX_CONFIG['model']['name']}")
    logger.info("‚ú® Chronex AI (Python Backend) is running on NEXCHAT - The future is initialized!")
    
    # Start the Flask server
    app.run(
        host='0.0.0.0',
        port=port,
        debug=debug,
        threaded=True
    ) 
